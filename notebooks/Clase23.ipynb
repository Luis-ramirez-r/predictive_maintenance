{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm\n",
    "#!pip install xlsxwriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from os.path import join\n",
    "import json \n",
    "import numpy as np \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../data/tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the files in the directory datadir\n",
    "#!rm -rf $datadir\n",
    "!mkdir -p $datadir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01 00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-01 00:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-01 00:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-01-01 00:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999995</td>\n",
       "      <td>999995</td>\n",
       "      <td>2000-01-12 13:46:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999996</td>\n",
       "      <td>999996</td>\n",
       "      <td>2000-01-12 13:46:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999997</td>\n",
       "      <td>999997</td>\n",
       "      <td>2000-01-12 13:46:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999998</td>\n",
       "      <td>999998</td>\n",
       "      <td>2000-01-12 13:46:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>999999</td>\n",
       "      <td>999999</td>\n",
       "      <td>2000-01-12 13:46:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A       B                date\n",
       "0            0       0 2000-01-01 00:00:00\n",
       "1            1       1 2000-01-01 00:00:01\n",
       "2            2       2 2000-01-01 00:00:02\n",
       "3            3       3 2000-01-01 00:00:03\n",
       "4            4       4 2000-01-01 00:00:04\n",
       "...        ...     ...                 ...\n",
       "999995  999995  999995 2000-01-12 13:46:35\n",
       "999996  999996  999996 2000-01-12 13:46:36\n",
       "999997  999997  999997 2000-01-12 13:46:37\n",
       "999998  999998  999998 2000-01-12 13:46:38\n",
       "999999  999999  999999 2000-01-12 13:46:39\n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '2000-01-01'\n",
    "nrows = 1000000\n",
    "\n",
    "# Generate sample data\n",
    "df = pd.DataFrame({'A': range(nrows), 'B': range(nrows)})\n",
    "num_of_seconds = 1000000\n",
    "dates = pd.date_range(start=start_date, periods=num_of_seconds, freq='S')\n",
    "\n",
    "df['date'] = dates\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to CSV file\n",
    "start_time = time.time()\n",
    "df.to_csv(join(datadir,'sample.csv') , index=False)\n",
    "csv_write_time = time.time() - start_time\n",
    "\n",
    "# Read data from CSV file\n",
    "start_time = time.time()\n",
    "pd.read_csv(join(datadir,'sample.csv'))\n",
    "csv_read_time = time.time() - start_time\n",
    "\n",
    "# Write data to Parquet file\n",
    "start_time = time.time()\n",
    "df.to_parquet(join(datadir,'sample.parquet'),  index=False)\n",
    "parquet_write_time = time.time() - start_time\n",
    "\n",
    "# Read data from Parquet file\n",
    "start_time = time.time()\n",
    "pd.read_parquet(join(datadir,'sample.parquet'))\n",
    "parquet_read_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Write a pickle file \n",
    "start_time = time.time()\n",
    "df.to_pickle(join(datadir,'sample.pkl'))\n",
    "pickle_write_time = time.time() - start_time\n",
    "\n",
    "# Read a pickle file\n",
    "start_time = time.time()\n",
    "pd.read_pickle\n",
    "pickle_read_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Write a json file\n",
    "start_time = time.time()\n",
    "df.to_json(join(datadir,'sample.json'))\n",
    "json_write_time = time.time() - start_time\n",
    "\n",
    "# Read a json file\n",
    "start_time = time.time()\n",
    "pd.read_json(join(datadir,'sample.json'))\n",
    "json_read_time = time.time() - start_time\n",
    "\n",
    "# Store all the metrics in a dictionary \n",
    "metrics = {'Format': ['CSV', 'Parquet', 'Pickle', 'JSON'],\n",
    "              'Write Time': [csv_write_time, parquet_write_time, pickle_write_time,json_write_time],\n",
    "                'Read Time': [csv_read_time, parquet_read_time, pickle_read_time,  json_read_time]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Write Time</th>\n",
       "      <th>Read Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSV</td>\n",
       "      <td>3.492784</td>\n",
       "      <td>0.727808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parquet</td>\n",
       "      <td>0.451211</td>\n",
       "      <td>0.232760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pickle</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JSON</td>\n",
       "      <td>0.665769</td>\n",
       "      <td>5.140980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Format  Write Time  Read Time\n",
       "0      CSV    3.492784   0.727808\n",
       "1  Parquet    0.451211   0.232760\n",
       "2   Pickle    0.036722   0.000074\n",
       "3     JSON    0.665769   5.140980"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(metrics)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A        int64\n",
       "B        int64\n",
       "date    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the csv file \n",
    "df = pd.read_csv(join(datadir,'sample.csv'))\n",
    "# show the dtypes \n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A                int64\n",
       "B                int64\n",
       "date    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the parquet file \n",
    "df = pd.read_parquet(join(datadir,'sample.parquet'))\n",
    "# show the dtypes\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file as pickle \n",
    "df.to_pickle(join(datadir,'sample.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A                int64\n",
       "B                int64\n",
       "date    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pickle file \n",
    "df = pd.read_pickle(join(datadir,'sample.pkl'))\n",
    "# show the dtypes\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the write and read times for parquet and csv for different number of rows and columns \n",
    "\n",
    "\n",
    "datadir = '../data/tmp/'\n",
    "\n",
    "rows_list = [1000, 10000, 10000,100000,1000000]\n",
    "cols_list = [10]\n",
    "\n",
    "\n",
    "# create a dictionary to store the metrics\n",
    "metrics = {'nrows': [],\n",
    "            'ncols': [],\n",
    "            'Write Time CSV': [],\n",
    "            'Read Time CSV': [],\n",
    "            'Write Time Parquet': [],\n",
    "            'Read Time Parquet': []}\n",
    "\n",
    "# loop over the number of rows and columns\n",
    "# show the loop progress using tqdm \n",
    "for  nrows in tqdm(rows_list):\n",
    "    for ncols in cols_list:\n",
    "        # create a numpy matrix with nrows and ncols \n",
    "        data = np.random.rand(nrows, ncols)\n",
    "        # create a dataframe with the data\n",
    "        df = pd.DataFrame(data)\n",
    "        df.columns = df.columns.astype(str) \n",
    "\n",
    "        # write the data to a csv file\n",
    "        start_time = time.time()\n",
    "        df.to_csv(join(datadir,'sample.csv') , index=False)\n",
    "        csv_write_time = time.time() - start_time\n",
    "        # read the data from the csv file\n",
    "        start_time = time.time()\n",
    "        pd.read_csv(join(datadir,'sample.csv'))\n",
    "        csv_read_time = time.time() - start_time\n",
    "        # write the data to a parquet file\n",
    "        start_time = time.time()\n",
    "        df.to_parquet(join(datadir,'sample.parquet'),  index=False)\n",
    "        parquet_write_time = time.time() - start_time\n",
    "        # read the data from the parquet file\n",
    "        start_time = time.time()\n",
    "        pd.read_parquet(join(datadir,'sample.parquet'))\n",
    "        parquet_read_time = time.time() - start_time\n",
    "        # store the metrics in the dictionary\n",
    "        metrics['nrows'].append(nrows)\n",
    "        metrics['ncols'].append(ncols)\n",
    "        metrics['Write Time CSV'].append(csv_write_time)\n",
    "        metrics['Read Time CSV'].append(csv_read_time)\n",
    "        metrics['Write Time Parquet' ].append(parquet_write_time)\n",
    "        metrics['Read Time Parquet'].append(parquet_read_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics =  pd.DataFrame(metrics)\n",
    "\n",
    "# calculate the ratio of read and write times for csv and parquet \n",
    "metrics['Write Time CSV/Parquet'] = metrics['Write Time CSV']/metrics['Write Time Parquet']\n",
    "metrics['Read Time CSV/Parquet'] = metrics['Read Time CSV']/metrics['Read Time Parquet']\n",
    "# calculate the number of elements in the dataframe \n",
    "metrics['n_elements'] = metrics['nrows']*metrics['ncols'] \n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics\n",
    "\n",
    "# plot the ratio of read and write times for csv and parquet in log scale \n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "sns.lineplot(x='n_elements', y='Write Time CSV/Parquet', data=metrics, ax=ax[0])\n",
    "sns.lineplot(x='n_elements', y='Read Time CSV/Parquet', data=metrics, ax=ax[1])\n",
    "ax[0].set_xscale('log')\n",
    "ax[1].set_xscale('log')\n",
    "ax[0].set_yscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "ax[0].set_title('Write Time CSV/Parquet')\n",
    "ax[1].set_title('Read Time CSV/Parquet')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores de codificacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Name\":[\"John Smith\",\"Jane Doe\",\"Andrés García\"],\n",
    "        \"Age\": [35,28,42],\n",
    "        \"City\":[\"New York\",\"Los Angeles\",\"São Paulo\"]}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(join(datadir,\"enc_data.csv\") , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc3 in position 65: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# load the encoded file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(join(datadir,\u001b[39m\"\u001b[39;49m\u001b[39menc_data.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m),encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mascii\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m df\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[1;32m     83\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1965\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc3 in position 65: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# load the encoded file\n",
    "df = pd.read_csv(join(datadir,\"enc_data.csv\"),encoding='ascii')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:17<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## XLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5180/1539354232.py:18: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "# Create another dataframe\n",
    "df2 = pd.DataFrame({'A': [7, 8, 9], 'B': [10, 11, 12]})\n",
    "\n",
    "# Create a third dataframe\n",
    "df3 = pd.DataFrame({'A': [13, 14, 15], 'B': [16, 17, 18]})\n",
    "\n",
    "# Create an ExcelWriter object\n",
    "writer = pd.ExcelWriter(join(datadir,  'example.xlsx'  ) , engine='xlsxwriter')\n",
    "\n",
    "# Write each dataframe to a different sheet\n",
    "df1.to_excel(writer, sheet_name='Sheet1')\n",
    "df2.to_excel(writer, sheet_name='Sheet2')\n",
    "df3.to_excel(writer, sheet_name='Sheet3')\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first sheet of the Excel file\n",
    "df = pd.read_excel(join(datadir,  'example.xlsx'  ), sheet_name='Sheet1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"word\":\"example\",\"phonetic\":\"/əɡˈzæmpl̩/\",\"phonetics\":[{\"text\":\"/əɡˈzæmpl̩/\",\"audio\":\"\"},{\"text\":\"/ɘɡˈzɐːmpɯ/\",\"audio\":\"\"},{\"text\":\"/ɪɡˈzɑːmpl̩/\",\"audio\":\"\"},{\"text\":\"/əɡˈzæmpl̩/\",\"audio\":\"https://api.dictionaryapi.dev/media/pronunciations/en/example-us.mp3\",\"sourceUrl\":\"https://commons.wikimedia.org/w/index.php?curid=267013\"}],\"meanings\":[{\"partOfSpeech\":\"noun\",\"definitions\":[{\"definition\":\"Something that is representative of all such things in a group.\",\"synonyms\":[],\"antonyms\":[]},{\"definition\":\"Something that serves to illustrate or explain a rule.\",\"synonyms\":[],\"antonyms\":[]},{\"definition\":\"Something that serves as a pattern of behaviour to be imitated (a good example) or not to be imitated (a bad example).\",\"synonyms\":[],\"antonyms\":[]},{\"definition\":\"A person punished as a warning to others.\",\"synonyms\":[],\"antonyms\":[]},{\"definition\":\"A parallel or closely similar case, especially when serving as a precedent or model.\",\"synonyms\":[],\"antonyms\":[]},{\"definition\":\"An instance (as a problem to be solved) serving to illustrate the rule or precept or to act as an exercise in the application of the rule.\",\"synonyms\":[],\"antonyms\":[]}],\"synonyms\":[],\"antonyms\":[]},{\"partOfSpeech\":\"verb\",\"definitions\":[{\"definition\":\"To be illustrated or exemplified (by).\",\"synonyms\":[],\"antonyms\":[]}],\"synonyms\":[],\"antonyms\":[]}],\"license\":{\"name\":\"CC BY-SA 3.0\",\"url\":\"https://creativecommons.org/licenses/by-sa/3.0\"},\"sourceUrls\":[\"https://en.wiktionary.org/wiki/example\"]}]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "word = \"example\"\n",
    "url = f\"https://api.dictionaryapi.dev/api/v2/entries/en/{word}\"\n",
    "response = requests.get(url)\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'example',\n",
       "  'phonetic': '/əɡˈzæmpl̩/',\n",
       "  'phonetics': [{'text': '/əɡˈzæmpl̩/', 'audio': ''},\n",
       "   {'text': '/ɘɡˈzɐːmpɯ/', 'audio': ''},\n",
       "   {'text': '/ɪɡˈzɑːmpl̩/', 'audio': ''},\n",
       "   {'text': '/əɡˈzæmpl̩/',\n",
       "    'audio': 'https://api.dictionaryapi.dev/media/pronunciations/en/example-us.mp3',\n",
       "    'sourceUrl': 'https://commons.wikimedia.org/w/index.php?curid=267013'}],\n",
       "  'meanings': [{'partOfSpeech': 'noun',\n",
       "    'definitions': [{'definition': 'Something that is representative of all such things in a group.',\n",
       "      'synonyms': [],\n",
       "      'antonyms': []},\n",
       "     {'definition': 'Something that serves to illustrate or explain a rule.',\n",
       "      'synonyms': [],\n",
       "      'antonyms': []},\n",
       "     {'definition': 'Something that serves as a pattern of behaviour to be imitated (a good example) or not to be imitated (a bad example).',\n",
       "      'synonyms': [],\n",
       "      'antonyms': []},\n",
       "     {'definition': 'A person punished as a warning to others.',\n",
       "      'synonyms': [],\n",
       "      'antonyms': []},\n",
       "     {'definition': 'A parallel or closely similar case, especially when serving as a precedent or model.',\n",
       "      'synonyms': [],\n",
       "      'antonyms': []},\n",
       "     {'definition': 'An instance (as a problem to be solved) serving to illustrate the rule or precept or to act as an exercise in the application of the rule.',\n",
       "      'synonyms': [],\n",
       "      'antonyms': []}],\n",
       "    'synonyms': [],\n",
       "    'antonyms': []},\n",
       "   {'partOfSpeech': 'verb',\n",
       "    'definitions': [{'definition': 'To be illustrated or exemplified (by).',\n",
       "      'synonyms': [],\n",
       "      'antonyms': []}],\n",
       "    'synonyms': [],\n",
       "    'antonyms': []}],\n",
       "  'license': {'name': 'CC BY-SA 3.0',\n",
       "   'url': 'https://creativecommons.org/licenses/by-sa/3.0'},\n",
       "  'sourceUrls': ['https://en.wiktionary.org/wiki/example']}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>math</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A001</td>\n",
       "      <td>Tom</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>James</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A003</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   name  math  physics  chemistry\n",
       "0  A001    Tom    60       66         61\n",
       "1  A002  James    89       76         51\n",
       "2  A003  Jenny    79       90         78"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \n",
    "# De una URL\n",
    "URL = 'http://raw.githubusercontent.com/BindiChen/machine-learning/master/data-analysis/027-pandas-convert-json/data/simple.json'\n",
    "df = pd.read_json(URL)\n",
    "df.head(10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nested_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>math</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A001</td>\n",
       "      <td>Tom</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>James</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A003</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   name  math  physics  chemistry\n",
       "0  A001    Tom    60       66         61\n",
       "1  A002  James    89       76         51\n",
       "2  A003  Jenny    79       90         78"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizar los datos\n",
    "with open('../data/other/nested_json.json','r') as f:\n",
    "    data = json.loads(f.read())# Flatten data\n",
    "df_nested_list = pd.json_normalize(data, record_path =['students'])\n",
    "df_nested_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>math</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A001</td>\n",
       "      <td>Tom</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>James</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A003</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   name  math  physics  chemistry\n",
       "0  A001    Tom    60       66         61\n",
       "1  A002  James    89       76         51\n",
       "2  A003  Jenny    79       90         78"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizar los datos\n",
    "with open('../data/other/nested_json.json','r') as f:\n",
    "    data = json.loads(f.read())# Flatten data\n",
    "df_nested_list = pd.json_normalize(data, record_path =['students'])\n",
    "df_nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>math</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "      <th>school_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A001</td>\n",
       "      <td>Tom</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>ABC primary school</td>\n",
       "      <td>Year 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>James</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "      <td>ABC primary school</td>\n",
       "      <td>Year 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A003</td>\n",
       "      <td>Jenny</td>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "      <td>ABC primary school</td>\n",
       "      <td>Year 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   name  math  physics  chemistry         school_name   class\n",
       "0  A001    Tom    60       66         61  ABC primary school  Year 1\n",
       "1  A002  James    89       76         51  ABC primary school  Year 1\n",
       "2  A003  Jenny    79       90         78  ABC primary school  Year 1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combinando\n",
    "df_nested_list = pd.json_normalize(\n",
    "    data, \n",
    "    record_path =['students'], \n",
    "    meta=['school_name', 'class']\n",
    ")\n",
    "df_nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
